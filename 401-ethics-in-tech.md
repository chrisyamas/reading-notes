# Notes on Ethics in Tech

## Ethics in the workplace

[Google Backtracks, Says Its AI Will Not Be Used for Weapons or Surveillance](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327) by Kate Conger for Gizmodo, 2018

After external and internal (from Google employees) pressure, Google released a statement declaring a new set of "principles" regarding how they will allow AI that they develop to be used. This was done in response to pushback against Project Maven, a partnership between Google and the U.S. Department of Defense that uses AI to analyze footage from drones.

Many Google employees, activists, and watchdog entities remain skeptical that the statement would actually preclude the company from actually engaging in Project Maven or similar projects in the future.

Personally, I found the use of ambiguous terms like "socially beneficial" and "overall harm" in the statement to leave a lot of wiggle room for Google. The Pentagon has consistently made the case that drones (a.k.a. unmanned aerial vehicles or UAVs) exist to reduce the "overall harm" inherent to military operations. They, of course, also argue that the U.S. only uses its military for "socially beneficial" (i.e. containing, combatting, and eliminating perceived threats to American interests).

Google is a publicly traded corporation, which means they're first priority must be to meeting the demands of their shareholders. In addition to hearing from Google employees, I would have been interested to hear perspectives from long-term, high-stake shareholders of Google stock to hear whether they would prefer the company reject or not seek lucrative government contracts to preserve an adherence to a "do no harm" policy for their AI usage.

## Ethics in Technology

[Morality, ethics of a self-driving car: Who decides who lives, dies?](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/) by Todd Spangler in the Detroit Free Press, 2017

While the promise offered by self-driving cars (a.k.a. autonomous vehicles, or AVs) is a future where tens of thousands of lives that would have been lost to human-error-caused traffic accidents, the reality is that the road to getting there involves literal life-and-death programming. The software that will guide the AVs we will share the road with (and perhaps be passengers in) will be given instructions for how to react in zero-sum, no-win situations. The most extreme are those which a program will decide whose lives to prioritize in the event of an impending high-speed collision: slam on the breaks and still hit the pedestrian who ran out into the road, swerve left and hit the school bus, or swerve right and the driver might die. We accept the outcomes of these tragic situations when a human with a conscience is the one behind the wheel, but most people are uncomfortable at this point with the outcomes essentially being "predetermined" (or rather, built) into the software.

This article is old, from nearly five years ago, so much progress has been made on developing AVs since then. But the moral questions remain. And as in even the most basic whiteboarding problem, the edge cases are where the most significant impacts or problems will arise. Unlike a LeetCode problem, the number of fluid factors that arise in a real-life automotive issue are staggering: speed, situation, weather conditions, mechanical performance (just to name a few).

What really sticks out at me is how important it will be to have consistent standards for programming across all makes and models, and across the entire United States (ideally international standards as well, at least continent-specific ones). To have the best chance at saving lives, the software driving an AV should be able to predict with reasonable accuracy how the other vehicles in a situation will behave.

I have also wondered about the issue of security: will cars be relatively easily hackable? Car softare hacking has [already been an issue](https://www.cnet.com/roadshow/news/2019-automotive-cyber-hack-security-study-upstream/), so we would need to really get a handle on things before AVs can have wide usage. [This WIRED article] from 2015 (https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/) paints a terrifying picture as well. While the assigned reading on AVs is mostly concerned with the decisions made by the software, I'm also concerned about the actions that could be taken to override the software by those seeking to cause harm or terrorize.
