# Notes on Serverless Computing

## What is serverless?

**serverless** - a cloud computing model that does three key things automatically:

1. provisions the computing resources required to run application code on demand, or in respond to a specific event;
2. scales those resources up or down in response to increased or decreased demand;
3. scales resources to zero when the application stops running

- all management of backend cloud infrastructure and operations tasks are handled by the cloud provider, to developers can devote more time to developing and optimizing front-end app and business logic
- customers never pay for unused capacity, only the resources to run the app and only when its being used
- there are certainly servers involved, they're just invisible to the client
- Amazon Web Services introduced serverless in 2014 w/ AWS Lambda. Today there's Microsoft Azure (Azure Functions), Google Cloud (Google Cloud Functions), and IBM Cloud (IBM Cloud Code Engine).

the triumvirate core of cloud-native app development is comprised of:

1. serverless
2. microservices
3. containers

### Serverless vs. FaaS

- FaaS: function as a service; a subset of serverless; the compute paradigm at its core where app code or contains run only in response to events or requests
- Serverless is comprised of: FaaS, storage, databases, networks, API gateways, authentication, etc that support the code

## Serverless pros and cons

### Pros

- gives developers more time to work on front-end code, not managing infrastructure
- only execution is paid for, not unused resources (unlike in IaaS, infrastructure as a service, where customers pay for VMs to be on reserve for use for entire commission of time)
- serverless is polyglot: allows for all programming languages
- simplifies development and DevOps cycles since developers don't need to describe the infrastructure
- can be faster and more cost-effective for certain workloads (i.e. w/ parallel processing)
- near-total visibility into systems and user times, and can systematically collect that data

### Cons

- not as cost-effective for predictable, steady, long-running processes; those should enlist a traditional server environment
- sometimes the delay resulting from cold starts (scaling up from zero to serve a new request) can be unacceptable to clients
- can sometimes be difficult or impossible for dev teams to monitor or debug serverless functions using existing tools or processes
- material, or vendor, lock-in (i.e. having built so much of your app around the backend infrastructure of a particular cloud provider that you would incur a significant setback by trying to leave in them favor of a competitor or a traditional server environment)
